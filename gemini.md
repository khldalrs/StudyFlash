Google models

bookmark_border
Stay organized with collections
Save and categorize content based on your preferences.
Dismiss
Got it
Release Notes

Vertex AI features a growing list of foundation models that you can test, deploy, and customize for use in your AI-based applications. Foundation models are fine-tuned for specific use cases and offered at different price points. This page summarizes the models that are available in the various APIs and gives you guidance on which models to choose by use case.

For more information about all AI models and APIs on Vertex AI, see Explore AI models in Model Garden.

Gemini models
The following table summarizes the models available in the Gemini API. For more information about API details, see the Gemini API reference.

To explore a model in the Google Cloud console, select its model card in the Model Garden.

Model Inputs Outputs Use case Try the model
Gemini 2.0 Flash Thinking Mode
Text, images Text Provides stronger reasoning capabilities and includes the thinking process in responses. Try the Thinking Mode model
Gemini 2.0 Flash
Text, code, images, audio, video, video with audio, PDF Text, audio, images Provides next generation features, superior speed, native tool use, and multimodal generation. Try the Gemini 2.0 Flash model
Gemini 1.5 Flash
Text, code, images, audio, video, video with audio, PDF Text Provides speed and efficiency for high-volume, quality, cost-effective apps. Try the Gemini 1.5 Flash model
Gemini 1.5 Pro
Text, code, images, audio, video, video with audio, PDF Text Supports text or chat prompts for a text or code response.
Supports long-context understanding up to the maximum input token limit. Try the Gemini 1.5 Pro model
Gemini 1.0 Pro
Text Text The best performing model for a wide range of text-only tasks. Go to the Gemini 1.0 Pro model card
Gemini 1.0 Pro Vision
Text, images, audio, video, video with audio, PDF Text The best performing image and video understanding model to handle a broad range of applications. Try the Gemini 1.0 Pro Vision model
The following information provides details for each Gemini model.

Thinking Mode
Gemini 2.0 Flash
Gemini 1.5 Flash
Gemini 1.5 Pro
Gemini 1.0 Pro
More
Description
Gemini 2.0 Flash Thinking Mode is an experimental test-time compute model that's trained to generate the "thinking process" the model goes through as part of its response. As a result, Thinking Mode is capable of stronger reasoning capabilities in its responses than the base Gemini 2.0 Flash model.

For more information, see our Gemini 2.0 Flash Thinking Mode documentation.

Capabilities
Capability Availability
Grounding No
Tuning No
System instruction No. See Use system instructions.
JSON support No
Provisioned Throughput No. See Supported models.
Specifications
Specification
Max input tokens: 32,760
Max output tokens: 8,192
Training data: Up to May 2024
